#!/usr/bin/env python
# coding: utf-8

# Librerías necesarias

import tensorflow as tf
import os
import numpy as np
import sklearn as sk
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LeakyReLU, PReLU, GlobalAveragePooling2D
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input
from keras.initializers import Constant
from tensorflow.keras import regularizers
from glob import glob
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

# Rutas de las imágenes de entrenamiento y prueba
train_dir = 'data_malevis/train'
test_dir = 'data_malevis/val'

# Parámetros de preprocesamiento de imágenes
image_size = (224, 224)  # Tamaño deseado de las imágenes
batch_size = 32          # Tamaño del lote para el entrenamiento

# Generadores de datos para cargar y preprocesar las imágenes de entrenamiento y prueba
train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  # Normaliza los valores de píxeles entre 0 y 1
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical')

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False)

# Para obtener las clases de salida
classes = glob('malware_detection/data_malevis/train/*')

# Número de clases de salida
num_classes = len(classes)

# Arquitectura de la red neuronal 1 (MobileNetV2 con última capa adaptada)
base_model = MobileNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))
model1 = Sequential()

# Añadir al modelo todas menos la última
for layer in base_model.layers[:-1]:
  model1.add(layer)

# Congelar las ya entrenadas
for layer in model1.layers:
  layer.trainable=False

# Última capa
model1.add(Dense(num_classes, activation='softmax'))

# Compilación y entrenamiento del modelo
model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model1.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model1.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model1.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes
report = classification_report(y_true, y_pred, output_dict=True)

df = pd.DataFrame(report).T
df.to_excel('report_model1_mobilenetv2.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.show()

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.show()

# Arquitectura de la red neuronal 2 (MobileNetV2 + nuevas capas de clasificación con RELU)
base_model = MobileNetV2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))

# Freeze convolutinal layers
base_model.trainable = False

x = base_model.output

# Capas sustituidas
x = GlobalAveragePooling2D()(x)
top = Dense(units=num_classes, activation='softmax')(x)
model2 = Model(inputs=base_model.input, outputs=top)

# Compilación y entrenamiento del modelo
model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model2.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model2.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model2.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes
report = classification_report(y_true, y_pred, output_dict=True)

df = pd.DataFrame(report).T
df.to_excel('report_model2_mobilenetv2.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.show()

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.show()
