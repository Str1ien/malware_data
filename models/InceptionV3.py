#!/usr/bin/env python
# coding: utf-8

# Librerías necesarias
import tensorflow as tf
import os
import numpy as np
import sklearn as sk
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LeakyReLU, PReLU, GlobalAveragePooling2D
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
from tensorflow.keras.initializers import Constant
from tensorflow.keras import regularizers
from glob import glob
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import classification_report

# Rutas de las imágenes de entrenamiento y prueba
train_dir = 'data_malevis/train'
test_dir = 'data_malevis/val'

# Parámetros de preprocesamiento de imágenes
image_size = (224, 224)  # Tamaño deseado de las imágenes
batch_size = 32          # Tamaño del lote para el entrenamiento

# Generadores de datos para cargar y preprocesar las imágenes de entrenamiento y prueba
train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  # Normaliza los valores de píxeles según el modelo de CNN
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical')

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False)

# Para obtener las clases de salida
classes = glob('malware_detection/data_malevis/train/*')

# Número de clases de salida
num_classes = len(classes)

# Arquitectura de la red neuronal 2 (InceptionV3 + nuevas capas de clasificación con RELU)
base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))

# Freeze convolutinal layers
for layer in base_model.layers:
  layer.trainable = False

# Capas sustituidas
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(units=1024, activation='relu')(x)
top = Dense(units=num_classes, activation='softmax')(x)

model2 = Model(inputs=base_model.input, outputs=top)

# Compilación y entrenamiento del modelo
model2.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model2.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model2.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model2.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes

report = classification_report(y_true, y_pred, output_dict=True)
df = pd.DataFrame(report).T
df.to_excel('report_model2_inceptionv3.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.savefig('model2_loss.png')

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.savefig('model2_acc.png')

# Arquitectura de la red neuronal 3 (InceptionV3 + nuevas capas de clasificación con Leaky RELU)
base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))

# Freeze convolutinal layers
for layer in base_model.layers:
  layer.trainable = False

# Capas sustituidas
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(units=1024)(x)
x = LeakyReLU()(x)
top = Dense(units=num_classes, activation='softmax')(x)

model3 = Model(inputs=base_model.input, outputs=top)

# Compilación y entrenamiento del modelo
model3.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model3.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model3.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model3.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes

report = classification_report(y_true, y_pred, output_dict=True)
df = pd.DataFrame(report).T
df.to_excel('report_model3_inceptionv3.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.savefig('model3_loss.png')

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.savefig('model3_acc.png')

# Arquitectura de la red neuronal 4 (InceptionV3 + nuevas capas de clasificación con SELU)
base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))

# Freeze convolutinal layers
for layer in base_model.layers:
  layer.trainable = False

# Capas sustituidas
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(units=1024, activation='selu')(x)
top = Dense(units=num_classes, activation='softmax')(x)

model4 = Model(inputs=base_model.input, outputs=top)
#model4.summary()

# Compilación y entrenamiento del modelo
model4.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model4.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model4.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model4.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes

report = classification_report(y_true, y_pred, output_dict=True)
df = pd.DataFrame(report).T
df.to_excel('report_model4_inceptionv3.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss)

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.savefig('model4_loss.png')

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.savefig('model4_acc.png')

# Arquitectura de la red neuronal 5 (InceptionV3 + nuevas capas de clasificación con PReLU (inicializador Constant))
base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))

# Freeze convolutinal layers
for layer in base_model.layers:
  layer.trainable = False

# Capas sustituidas
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(units=1024)(x)
x = PReLU(alpha_initializer=Constant(value=0.25))(x)
top = Dense(units=num_classes, activation='softmax')(x)

model5 = Model(inputs=base_model.input, outputs=top)

# Compilación y entrenamiento del modelo
model5.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model5.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model5.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model5.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes

report = classification_report(y_true, y_pred, output_dict=True)
df = pd.DataFrame(report).T
df.to_excel('report_model5_inceptionv3.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.savefig('model5_loss.png')

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.savefig('model5_acc.png')

# Arquitectura de la red neuronal 6 (InceptionV3 + eLU)
base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))

# Freeze convolutinal layers
for layer in base_model.layers:
  layer.trainable = False

# Capas sustituidas
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(units=1024, activation='elu')(x)
top = Dense(units=num_classes, activation='softmax')(x)

model6 = Model(inputs=base_model.input, outputs=top)
# model6.summary()

# Compilación y entrenamiento del modelo
model6.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model6.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model6.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model6.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes

report = classification_report(y_true, y_pred, output_dict=True)
df = pd.DataFrame(report).T
df.to_excel('report_model6_inceptionv3.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.show()

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.show()


# Arquitectura de la red neuronal 7 (InceptionV3 + ELU + L2)
base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))

# Freeze convolutinal layers
for layer in base_model.layers:
  layer.trainable = False

# Capas sustituidas
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(units=1024, activation='elu', kernel_regularizer=regularizers.l2(0.001))(x)
top = Dense(units=num_classes, activation='softmax')(x)

model7 = Model(inputs=base_model.input, outputs=top)
# model7.summary()

# Compilación y entrenamiento del modelo
model7.compile(optimizer=tf.keras.optimizers.Adam(0.0003), loss='categorical_crossentropy', metrics=['accuracy'])
history = model7.fit(train_generator, epochs=10, validation_data=test_generator)

# Evaluación del modelo con los datos de test
loss, accuracy = model6.evaluate(test_generator)
print(f"Loss: {loss}, Accuracy: {accuracy}")

Y_pred = model7.predict(test_generator)
y_pred = np.argmax(Y_pred, axis=1)
y_true = test_generator.classes

report = classification_report(y_true, y_pred, output_dict=True)
df = pd.DataFrame(report).T
df.to_excel('report_model7_inceptionv3.xlsx', index_label='Class')

# for class_label, metrics in report.items():
#     if class_label.isdigit():
#         class_name = list(test_generator.class_indices.keys())[int(class_label)]
#         print(f"Class {class_label} ({class_name}):")
#         print(f"Loss: {loss}")
#         print(f"Accuracy: {accuracy}")
#         print(f"Precision: {metrics['precision']}")
#         print(f"Recall: {metrics['recall']}")
#         print(f"F1-Score: {metrics['f1-score']}")
#         print("-------------")

# Gráfica de pérdida (loss)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
# plt.show()

# Gráfica de precisión (accuracy)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
# plt.show()
